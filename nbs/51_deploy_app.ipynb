{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy\n",
    "\n",
    "Utilities to deploy app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp deploy.app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import json\n",
    "import requests\n",
    "from dataclasses import dataclass, field\n",
    "from importlib.machinery import SourceFileLoader\n",
    "from importlib.util import spec_from_loader, module_from_spec\n",
    "from pathlib import Path\n",
    "from textwrap import dedent\n",
    "from typing import Any, Union\n",
    "\n",
    "from black import Mode, format_file_contents\n",
    "from jinja2 import Template, DebugUndefined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporti\n",
    "PathStr = Union[Path, str]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy with Streamlit and NGROK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def deploy_app(app=\"app.py\", from_jupyter=True):\n",
    "    \"\"\"Deploy a streamlit app using ngrok\"\"\"\n",
    "    if not Path(app).is_file():\n",
    "        print(f\"ERROR: the app {app} does not exist!\")\n",
    "        return\n",
    "\n",
    "    if from_jupyter:\n",
    "        get_ipython().system_raw('ngrok http 8501 &')\n",
    "        resp = requests.get(\"http://localhost:4040/api/tunnels\")\n",
    "        tunnel = json.loads(resp.content)[\"tunnels\"][0]\n",
    "        local = tunnel[\"config\"][\"addr\"]\n",
    "        public = tunnel[\"public_url\"]\n",
    "    else:\n",
    "        raise NotImplementedError(f\"Deployment outside jupyter currently not supported\")\n",
    "\n",
    "    print(dedent(f\"\"\"\\\n",
    "        Let's create a tunnel to port {local.split(\":\")[-1]}!\n",
    "        1. Create in a cell : !nohup streamlit run {app}\n",
    "        2. Run that cell\n",
    "        3. Click on this link: {public}\n",
    "\n",
    "        Note: we recommend to put the the code `!nohup streamlit ...`\n",
    "        after this line of code (instead of a new dedicated cell).\n",
    "    \"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions to load a module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def load_module(module_path: PathStr, module_name=\"module\") -> Any:\n",
    "    \"\"\"Load and return a module\"\"\"\n",
    "    module_path = Path(module_path)\n",
    "    if not (module_path.is_file() and module_path.suffix == \".py\"):\n",
    "        raise AttributeError(f\"Module {module_path} not found or not a .py file\")\n",
    "    loader = SourceFileLoader(module_name, str(module_path))\n",
    "    spec = spec_from_loader(loader.name, loader)\n",
    "    if not spec:\n",
    "        raise AttributeError(f\"Empty module spec from {module_path}\")\n",
    "    module = module_from_spec(spec)\n",
    "    loader.exec_module(module)\n",
    "    return module\n",
    "\n",
    "\n",
    "def import_from_module(module_path: PathStr, name: str, module_name=\"module\") -> Any:\n",
    "    \"\"\"Import a list of names from a module from its path\"\"\"\n",
    "    module = load_module(module_path, module_name=module_name)\n",
    "    try:\n",
    "        return getattr(module, name)\n",
    "    except AttributeError:\n",
    "        raise AttributeError(f\"Name {name} not found in {module_path}\") from None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get template of App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def blackify(code:str) -> str:\n",
    "    \"\"\"Run \"black\" on a code passed as string\"\"\"\n",
    "    return format_file_contents(code, mode=Mode(), fast=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporti\n",
    "TEMPLATE_FLOW = \"\"\"\n",
    "from pathlib import Path\n",
    "\n",
    "import streamlit as st\n",
    "\n",
    "{{ specific_import }}\n",
    "{{ custom_import }}\n",
    "\n",
    "st.set_page_config(page_title=\"ML deployment, by unpackAI\", page_icon=\"ðŸš€\")\n",
    "st.image(\"https://unpackai.github.io/unpackai_logo.svg\")\n",
    "st.title(\"{{ title }}\")\n",
    "st.write(\"*by {{ author }}*\")\n",
    "st.write(\"---\")\n",
    "\n",
    "{{ load_model }}\n",
    "\n",
    "{{ display_prediction }}\n",
    "\n",
    "{{ input_2_prediction }}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TemplateCode:\n",
    "    specific_import: str = \"\"\n",
    "    load_model: str = \"\"\n",
    "    display_prediction: str = \"\"\n",
    "    input_2_prediction: str = \"\"\"\\\n",
    "        select = st.sidebar.radio(\"How to load {{ input }}?\", [\"from file{% if multiple %}s{% endif %}\", \"from URL\"])\n",
    "        st.sidebar.write(\"---\")\n",
    "\n",
    "        if select == \"from URL\":\n",
    "            url = st.sidebar.text_input(\"url\")\n",
    "            if url:\n",
    "                display_prediction(url)\n",
    "\n",
    "        else:\n",
    "            {% if multiple -%}\n",
    "            files = st.sidebar.file_uploader(\"Choose {{ input }}\", accept_multiple_files=True)\n",
    "            for file in files:  # type:ignore # this is an iterable\n",
    "                display_prediction(file)\n",
    "            {% else -%}\n",
    "            file = st.sidebar.file_uploader(\"Choose {{ input }}\")\n",
    "            if file:\n",
    "                display_prediction(file)\n",
    "            {% endif %}\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Templates for CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporti\n",
    "\n",
    "# NOTE: We need re-implementation of elements defined during loading\n",
    "\n",
    "TEMPLATE_CV_FASTAI = TemplateCode(\n",
    "    specific_import=\"\"\"\n",
    "        {# The âœ¨ below is to go around import modification by nbdev #}\n",
    "        from {# âœ¨ #}unpackai.deploy.cv import get_image, get_learner, dummy_function\n",
    "    \"\"\"\n",
    "        ,\n",
    "    load_model=\"\"\"\\\n",
    "        {{ implem_4_model }}\n",
    "\n",
    "        learn = get_learner(Path(__file__).parent / \"{{ model }}\")\n",
    "        vocab = learn.dls.vocab\n",
    "    \"\"\",\n",
    "    display_prediction=\"\"\"\n",
    "        def display_prediction(pic):\n",
    "            img = get_image(pic)\n",
    "            with learn.no_bar():\n",
    "                prediction, idx, probabilities = learn.predict(img)\n",
    "            col_img, col_pred = st.columns(2)\n",
    "            col_img.image(img, caption=getattr(pic, \"name\", None))\n",
    "            col_pred.write(f\"### {prediction}\")\n",
    "            col_pred.metric(f\"Probability\", f\"{probabilities[idx].item()*100:.2f}%\")\n",
    "    \"\"\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Templates for Tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporti\n",
    "\n",
    "# NOTE: Loading model and prediction depends on the module (e.g. \"regression\")\n",
    "\n",
    "TEMPLATE_TABULAR_PYCARET = TemplateCode(\n",
    "    specific_import=\"\"\"\n",
    "        import pandas as pd\n",
    "        from pycaret.{{ module }} import load_model, predict_model\n",
    "    \"\"\",\n",
    "    load_model=\"\"\"model = load_model(\"{{ model }}\")\"\"\",\n",
    "    display_prediction=\"\"\"\n",
    "        def display_prediction(csv):\n",
    "            df = pd.read_csv(csv)\n",
    "            predictions = predict_model(model, data = df)\n",
    "            st.dataframe(predictions)\n",
    "    \"\"\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Templates for NLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporti\n",
    "TEMPLATE_NLP_HF = TemplateCode(\n",
    "    specific_import=\"\"\"\n",
    "        # TODO\n",
    "    \"\"\",\n",
    "    load_model=\"\"\"\n",
    "        # TODO\n",
    "    \"\"\",\n",
    "    display_prediction=\"\"\"\n",
    "        def display_prediction(csv:PathStr):\n",
    "            pass # TODO\n",
    "    \"\"\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class to Create Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporti\n",
    "\n",
    "LIST_TEMPLATES = {\n",
    "    \"CV\": {\"fastai\": TEMPLATE_CV_FASTAI},\n",
    "    \"Tabular\": {\"pycaret\": TEMPLATE_TABULAR_PYCARET},\n",
    "    \"NLP\": {\"hugging_face\": TEMPLATE_NLP_HF},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@dataclass\n",
    "class StreamlitApp:\n",
    "    \"\"\"Class to generate Streamlit App for different applications\n",
    "\n",
    "    Available applications: \"CV\", \"Tabular\", \"NLP\", and \"Custom\"\n",
    "    \"\"\"\n",
    "\n",
    "    application: str\n",
    "    framework: str = field(init=False, default=\"\")\n",
    "    content: str = field(init=False, default=\"\")\n",
    "    _title: str = field(init=False, default=\"Streamlit App\")\n",
    "\n",
    "    def __post_init__(self):\n",
    "        applications = list(LIST_TEMPLATES)\n",
    "        if self.application not in applications:\n",
    "            raise AttributeError(\n",
    "                f\"ERROR: Application {self.application} not supported. \"\n",
    "                f\"Available applications: {applications}\"\n",
    "            )\n",
    "\n",
    "    @property\n",
    "    def template(self) -> Template:\n",
    "        \"\"\"Get the template\"\"\"\n",
    "        base_template = Template(TEMPLATE_FLOW, undefined=DebugUndefined)\n",
    "        try:\n",
    "            template_framework = LIST_TEMPLATES[self.application][self.framework]\n",
    "        except KeyError as missing:\n",
    "            raise AttributeError(f\"Element {missing} not found among list of templates\")\n",
    "\n",
    "        return Template(\n",
    "            base_template.render(\n",
    "                specific_import=dedent(template_framework.specific_import),\n",
    "                load_model=dedent(template_framework.load_model),\n",
    "                display_prediction=dedent(template_framework.display_prediction),\n",
    "                input_2_prediction=dedent(template_framework.input_2_prediction),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def _render(\n",
    "        self,\n",
    "        framework: str,\n",
    "        title: str,\n",
    "        author: str,\n",
    "        model: PathStr,\n",
    "        custom_import: str = \"\",\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"Generic function for rendering\"\"\"\n",
    "        self.framework = framework\n",
    "        self._title = title\n",
    "        input_ = {\n",
    "            \"CV\": \"images\",\n",
    "            \"Tabular\": \"CSV\",\n",
    "            \"NLP\": \"Text\",\n",
    "        }.get(self.application, \"input\")\n",
    "        self.content = self.template.render(\n",
    "            title=title,\n",
    "            author=author,\n",
    "            model=model,\n",
    "            input=input_,\n",
    "            multiple=(input_.endswith(\"s\")),\n",
    "            custom_import=custom_import,\n",
    "            **kwargs,\n",
    "        )\n",
    "        self.content = blackify(self.content)\n",
    "        return self\n",
    "\n",
    "    def render_fastai(\n",
    "        self,\n",
    "        title: str,\n",
    "        author: str,\n",
    "        model: PathStr,\n",
    "        implem_4_model: str,\n",
    "        custom_import: str = \"\",\n",
    "    ) -> \"StreamlitApp\":\n",
    "        \"\"\"Render an app based on template\n",
    "\n",
    "        Args:\n",
    "            title: title of the App\n",
    "            author: author of the App\n",
    "            model: path of .pkl model to load (exported with `learn.export(...)`)\n",
    "            implem_4_model: extra implementations needed to load the model\n",
    "                (e.g. function used for labelling)\n",
    "            custom_import: custom import (optional)\n",
    "        \"\"\"\n",
    "        return self._render(\n",
    "            \"fastai\",\n",
    "            title,\n",
    "            author,\n",
    "            model,\n",
    "            implem_4_model=dedent(implem_4_model),\n",
    "            custom_import=custom_import,\n",
    "        )\n",
    "\n",
    "    def render_pycaret(\n",
    "        self,\n",
    "        title: str,\n",
    "        author: str,\n",
    "        model: PathStr,\n",
    "        module: str,\n",
    "        custom_import: str = \"\",\n",
    "    ) -> \"StreamlitApp\":\n",
    "        \"\"\"Render an app based on template\n",
    "\n",
    "        Args:\n",
    "            title: title of the App\n",
    "            author: author of the App\n",
    "            model: path of .pkl model to load (exported with `learn.export(...)`)\n",
    "            module: regression, classification, etc.\n",
    "            custom_import: custom import (optional)\n",
    "        \"\"\"\n",
    "        return self._render(\n",
    "            \"pycaret\",\n",
    "            title,\n",
    "            author,\n",
    "            model.replace(\".pkl\", \"\"),\n",
    "            module=module,\n",
    "            custom_import=custom_import,\n",
    "        )\n",
    "\n",
    "    def append(self, content: str) -> \"StreamlitApp\":\n",
    "        \"\"\"Add additional content to the app\"\"\"\n",
    "        self.content += dedent(content)\n",
    "        return self\n",
    "\n",
    "    def save(self, dest: PathStr, show=False):\n",
    "        \"\"\"Write the app to a file\"\"\"\n",
    "        Path(dest).write_text(self.content, encoding=\"utf-8\")\n",
    "        print(f\"Saved app '{self._title}' to '{dest}'\")\n",
    "        if show:\n",
    "            print(\"-\" * 20)\n",
    "            print(self.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporti\n",
    "TEMPLATE_CUSTOM = TemplateCode(\n",
    "    specific_import=\"{{ specific_import }}\",\n",
    "    load_model=\"\",\n",
    "    display_prediction=\"\",\n",
    "    input_2_prediction=\"{{ make_predictions }}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@dataclass\n",
    "class StreamlitAppCustom:\n",
    "    \"\"\"Application with custom implementation\"\"\"\n",
    "\n",
    "    content: str = field(init=False, default=\"\")\n",
    "    _title: str = field(init=False, default=\"Streamlit App\")\n",
    "\n",
    "    def render(\n",
    "        self,\n",
    "        title: str,\n",
    "        author: str,\n",
    "        make_predictions: Union[str, Path],\n",
    "        custom_import: str = \"\",\n",
    "    ) -> \"StreamlitAppCustom\":\n",
    "        \"\"\"Render an app based on template\n",
    "\n",
    "        Args:\n",
    "            title: title of the App\n",
    "            author: author of the App\n",
    "            make_predictions: custom implementations, either code or file path\n",
    "                if a file is provided, it shall implement the function\n",
    "                'def make_predictions()'\n",
    "            custom_import: custom import (optional)\n",
    "        \"\"\"\n",
    "        self._title = title\n",
    "        base_template = Template(TEMPLATE_FLOW, undefined=DebugUndefined)\n",
    "        template = Template(\n",
    "            base_template.render(\n",
    "                specific_import=dedent(TEMPLATE_CUSTOM.specific_import),\n",
    "                load_model=dedent(TEMPLATE_CUSTOM.load_model),\n",
    "                display_prediction=dedent(TEMPLATE_CUSTOM.display_prediction),\n",
    "                input_2_prediction=dedent(TEMPLATE_CUSTOM.input_2_prediction),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if isinstance(make_predictions, str) and not make_predictions.endswith(\".py\"):\n",
    "            self.content = template.render(\n",
    "                title=title,\n",
    "                author=author,\n",
    "                specific_import=\"\",\n",
    "                make_predictions=dedent(make_predictions),\n",
    "                custom_import=custom_import,\n",
    "            )\n",
    "        elif isinstance(make_predictions, Path) or make_predictions.endswith(\".py\"):\n",
    "            loaded_make_predictions = f\"\"\"\\\n",
    "                make_predictions = import_from_module(r\"{make_predictions}\", \"make_predictions\")\n",
    "                make_predictions()\n",
    "            \"\"\"\n",
    "            self.content = template.render(\n",
    "                title=title,\n",
    "                author=author,\n",
    "                specific_import=\"from unpackai.deploy.app import import_from_module\",\n",
    "                make_predictions=dedent(loaded_make_predictions),\n",
    "                custom_import=custom_import,\n",
    "            )\n",
    "        else:\n",
    "            raise AttributeError(\n",
    "                f\"Incorrect type for {make_predictions}: shall be code or .py path\"\n",
    "            )\n",
    "\n",
    "        self.content = blackify(self.content)\n",
    "        return self\n",
    "\n",
    "    def save(self, dest: PathStr, show=False):\n",
    "        \"\"\"Write the app to a file\"\"\"\n",
    "        Path(dest).write_text(self.content, encoding=\"utf-8\")\n",
    "        print(f\"Saved app '{self._title}' to '{dest}'\")\n",
    "        if show:\n",
    "            print(\"-\" * 20)\n",
    "            print(self.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# To be able to run the tests in the Notebook\n",
    "from pathlib import Path\n",
    "import ipytest\n",
    "import sys\n",
    "\n",
    "ipytest.autoconfig()\n",
    "\n",
    "root_dir = Path(\"..\").resolve()\n",
    "sys.path.append(str(root_dir / \"test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exportest\n",
    "# For Test Cases (might have duplicate import because it will be in a dedicated file)\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "import pytest\n",
    "from test_common.utils_4_tests import DATA_DIR, diff_files\n",
    "\n",
    "DEPLOY_DATA_DIR = DATA_DIR / \"deploy\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exportest\n",
    "def test_streamlit_cv_fastai(tmp_path):\n",
    "    \"\"\"Test Streamlit app for CV with fastai\"\"\"\n",
    "    dest = tmp_path / \"app_cv_fastai.py\"\n",
    "    StreamlitApp(\"CV\").render_fastai(\n",
    "        title=\"Is it a cat?\",\n",
    "        author=\"Jeff\",\n",
    "        model=\"model.pkl\",\n",
    "        implem_4_model=\"is_cat = dummy_function\",\n",
    "    ).append(\n",
    "        \"\"\"\n",
    "        st.sidebar.write(\"---\")\n",
    "        st.sidebar.button(\"Show Balloons\", on_click=st.balloons)\n",
    "        \"\"\"\n",
    "    ).save(\n",
    "        dest=dest\n",
    "    )\n",
    "\n",
    "    assert diff_files(DEPLOY_DATA_DIR / \"app_CV.py\", dest, show=True) == \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exportest \n",
    "def test_streamlit_tabular_pycaret(tmp_path):\n",
    "    \"\"\"Test Streamlit app for Tabular with pycaret\"\"\"\n",
    "    dest = tmp_path / \"app_tabular_pycaret.py\"\n",
    "    StreamlitApp(\"Tabular\").render_pycaret(\n",
    "        title=\"My Mini Tabular App\",\n",
    "        author=\"Jeff\",\n",
    "        model=\"model.pkl\",\n",
    "        module=\"regression\",\n",
    "    ).save(dest=dest)\n",
    "\n",
    "    assert diff_files(DEPLOY_DATA_DIR / \"app_Tabular.py\", dest, show=True) == \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exportest\n",
    "def test_custom_app_code(tmp_path):\n",
    "    \"\"\"Test custom app with code provided via string\"\"\"\n",
    "    dest = tmp_path / \"app_custom_code.py\"\n",
    "    code = \"\"\"\n",
    "        st.write(\"hello\")\n",
    "        st.balloons()\n",
    "    \"\"\"\n",
    "    StreamlitAppCustom().render(\n",
    "        \"Custom App\", \"Jeff\", code\n",
    "    ).save(dest=dest)\n",
    "\n",
    "    assert diff_files(DEPLOY_DATA_DIR / \"app_custom.py\", dest, show=True) == \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exportest\n",
    "def test_custom_app_external(tmp_path):\n",
    "    \"\"\"Test custom app with code provided via string\"\"\"\n",
    "    dest = tmp_path / \"app_custom_external.py\"\n",
    "\n",
    "    StreamlitAppCustom().render(\n",
    "        \"Custom App\", \"Jeff\", DEPLOY_DATA_DIR / \"correct_code_for_custom_app.py\"\n",
    "    ).save(dest=dest)\n",
    "\n",
    "    # Because we have a absolute path of \"test_data/deploy\", we will replace by relative path\n",
    "    # otherwise our tests will always be failed\n",
    "    content = dest.read_text(encoding=\"utf-8\").replace(str(DEPLOY_DATA_DIR), \"<deploy_dir>\")\n",
    "    content = content.replace(\">\\\\\", \">/\").replace('r\"<deploy_dir>/', 'Path(__file__).parent / \"')\n",
    "    dest.write_text(content, encoding=\"utf-8\")\n",
    "\n",
    "    assert diff_files(DEPLOY_DATA_DIR / \"app_custom_external.py\", dest, show=True) == \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                                                         [100%]\u001b[0m##vso[results.publish type=JUnit;runTitle='Pytest results';]e:\\AnsysDev\\_perso_repo\\unpackai\\nbs\\test-output.xml\n",
      "##vso[task.logissue type=warning;]Coverage XML was not created, skipping upload.\n",
      "\n",
      "------------ generated xml file: e:\\AnsysDev\\_perso_repo\\unpackai\\nbs\\test-output.xml -------------\n",
      "\u001b[32m\u001b[32m\u001b[1m4 passed\u001b[0m\u001b[32m in 0.27s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ipytest.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
